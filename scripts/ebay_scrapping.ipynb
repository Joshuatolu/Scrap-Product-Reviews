{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap Data from EBay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "\n",
    "from selenium.webdriver.common.by import By # to find tags or elements\n",
    "from selenium.webdriver.support.ui import WebDriverWait # a good way to wait\n",
    "from selenium.webdriver.support import expected_conditions as EC # for scrolling\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get product details\n",
    "def get_product_details(driver):\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Extract product details\n",
    "    feature_list = soup.find('div', class_ = 'kdwhd-description').find_all('ul')\n",
    "    features = []\n",
    "    if feature_list:\n",
    "        feature_items = feature_list[0].find_all('li')\n",
    "        for feature in feature_items:\n",
    "            features.append(feature.get_text(strip=True))\n",
    "\n",
    "    product_details = {\n",
    "        'product_name': soup.find('span', class_='ux-textspans ux-textspans--BOLD').text.strip(),\n",
    "        # 'brand': soup.find('div', class_='-pvxs').find_all('a')[0].text.strip(),\n",
    "        'price': int(re.sub(r'[^\\d]', '', soup.find('div', class_='x-price-primary').find('span').text.strip()))*1500,\n",
    "        # 'description': soup.find('div', class_='markup -mhm -pvl -oxa -sc').text.strip(),\n",
    "        'features': '. '.join(features) + '.',\n",
    "        'specification': soup.find('div', class_ = 'kdwhd-description').find('p').text.strip()\n",
    "    }\n",
    "\n",
    "    return product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Ebay product reviews\n",
    "def get_ebay_reviews(driver):\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    feedback_container = soup.find('ul', class_ = \"fdbk-detail-list__cards\")\n",
    "    all_feedbacks = feedback_container.find_all('li', class_ = \"fdbk-container\")\n",
    "\n",
    "    ebay_reviews = []\n",
    "\n",
    "    for feedbacks in all_feedbacks:\n",
    "        # Review Date\n",
    "        try:\n",
    "            review_date = feedbacks.find('span', class_ = \"fdbk-container__details__info__divide__time\").text\n",
    "        except AttributeError:\n",
    "            review_date = ''\n",
    "\n",
    "        # Reviewer Name\n",
    "        try:\n",
    "            name_text = feedbacks.find('div', class_ = \"fdbk-container__details__info__username\").text\n",
    "            reviewer_name = name_text.split('-')[0]\n",
    "        except AttributeError:\n",
    "            reviewer_name = ''\n",
    "\n",
    "        # Reviewer Comment\n",
    "        try:\n",
    "            reviewer_comment = feedbacks.find('div', class_ = 'fdbk-container__details__comment').text\n",
    "        except AttributeError:\n",
    "            reviewer_comment = ''\n",
    "\n",
    "        ebay_reviews.append({\n",
    "            'review_date' : review_date,\n",
    "            'reviewer_name' : reviewer_name,\n",
    "            'reviewer_comment' : reviewer_comment\n",
    "        })\n",
    "\n",
    "    return ebay_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scrap function\n",
    "def ebay_scrap(product_url):\n",
    "    # Configure Selenium EdgeDriver options\n",
    "    options = Options()\n",
    "    options.use_chromium = True\n",
    "    options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.59\") # code to prevent the website from detecting bot activity\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\") # Disable the automation line at the top of the browser\n",
    "    options.add_argument('headless')\n",
    "    options.add_argument('disable-gpu')\n",
    "    service = Service(executable_path=r'Driver\\msedgedriver.exe') # Always check to confirm that the version of edge driver matches the version or MS Edge browser\n",
    "    driver = webdriver.Edge(service=service, options=options) # Initialize the webdriver\n",
    "\n",
    "    driver.get(product_url)\n",
    "    time.sleep(8) # To load the product page\n",
    "\n",
    "    # Get the product details\n",
    "    product_details = get_product_details(driver)\n",
    "    product_name = re.split(r\"[\\'\\\"]\", product_details['product_name'])[0]\n",
    "\n",
    "    # Get the 'see more reviews' button\n",
    "    all_feedback_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable(\n",
    "        (By.XPATH, '//a[@class=\"fdbk-detail-list__tabbed-btn fake-btn fake-btn--large fake-btn--secondary\"]')\n",
    "    ))\n",
    "\n",
    "    # scroll down to where the button is\n",
    "    driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", all_feedback_button) # Scroll the page to view the button for Next Page\n",
    "    time.sleep(2)  # Wait for the scroll\n",
    "\n",
    "    # click the button\n",
    "    all_feedback_button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # The ewview opens up on another browser tab. Change driver focus to point to new page\n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Scrape all reviews - using a while loop\n",
    "    all_product_reviews = []\n",
    "\n",
    "    while True:\n",
    "        d_reviews = get_ebay_reviews(driver)\n",
    "        all_product_reviews.extend(d_reviews)\n",
    "\n",
    "        try:\n",
    "            # Get the next page button\n",
    "            next_page_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable(\n",
    "                (By.XPATH, '//a[@class=\"pagination__next icon-link\" and @aria-label=\"Next page\"]')\n",
    "            ))\n",
    "            # driver.find_element(By.XPATH, '//a[@aria-label=\"Next Page\"]')\n",
    "\n",
    "            # Scroll to the next page button area\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_page_button)\n",
    "            time.sleep(2)  # Wait for the scroll\n",
    "\n",
    "            next_page_button.click() # Clicks the next page button\n",
    "            time.sleep(5)  # Wait for the next page to load\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"No more pages to load\")\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Save to CSV\n",
    "    output_dir = r'Reviews\\Ebay'\n",
    "    file_name = f'{product_name}_reviews.csv'\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    product_df = pd.DataFrame(all_product_reviews)\n",
    "    product_df.to_csv(output_path, index=False)\n",
    "    print(f'{len(product_df)} {product_name} reviews successfully written to {output_path}! Nice work!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the start URL\n",
    "start_url = 'https://www.ebay.com/itm/254462710891?_skw=phone&epid=12019864188&itmmeta=01JMEAZEY3GMWKERYX7PYB1HCH&hash=item3b3f28d46b:g:tywAAOSwIpReYWMu&itmprp=enc%3AAQAKAAAA4FkggFvd1GGDu0w3yXCmi1cBdigaVfzLvfokvWKNvNFT%2B6qzkuicL0D%2FGnbsagx4u9M8pSJvwd7CZutUHbKvV2CfBHpjndCQ6zaEqqBLgGVmp%2BQBfyMXrJ3Qo6Xy3Bn3Z20g0GfJQM1ddiFL%2F6Kkv31Acl8weR%2FhErhCfvu0pW160YevJV2MhvHZIst%2FcqsS3Ybf4WgTJ5sb69yobsuhbh5JQsKF61w355FA5aLovsbkuqzH6XrMIaA0yI3HoDXf6wSB1vmOSlLsTi9l2%2BLL%2BZvuaLF%2BkV3r15PXKvWrE9hq%7Ctkp%3ABk9SR-jw_cqjZQ'\n",
    "# less review data - 'https://www.ebay.com/itm/385169573354?_skw=laptop+stand&itmmeta=01JKZQE3TG4DVJXYE7P5XDHPT0&hash=item59ade545ea:g:C-YAAOSw545i3usQ&itmprp=enc%3AAQAKAAAA0FkggFvd1GGDu0w3yXCmi1c%2Bw0OO6Zxtqq3No1Eqy4Ai8szJzA7faigTtPc%2FqhI8jKb9XsQo2NVfAOnfFOCDgRg9NcQ6qGjzopi0sinFhZHhsf79jAqtePIUbsTdXBQ7Q7ljUdbLStVWPyTq0uHuJp%2F3EUuNOggxP0rrpKW2dqgsneQ4RYNnCWrCO1iR2kEG20o82DNvspVMfUAZJkObB4wY0or%2FucpGjjDUwGyZCGdx3qy80gWdx3tNAyoPqOurVyNd3EEI6soQe7CE7b4GpcI%3D%7Ctkp%3ABk9SR8S9uPefZQ'\n",
    "# more review data - 'https://www.ebay.com/itm/385305869021?_skw=laptop+stand&itmmeta=01JKZQE3TGP5HCCWH64GZV6QX7&hash=item59b604fadd:g:lhgAAOSwzTJjolF5&itmprp=enc%3AAQAKAAAA0FkggFvd1GGDu0w3yXCmi1fmooQExts6zjYVSHvCsMZ%2FzF%2F8B6kR6bxlLKiMyCSmW9Bu8dy1cam%2BioAU%2Fz1Dk3ToONgmkfJZu%2BJ6tdiSotvjMJWO9%2FcDzg531PVtEfZCwyNlkjGiZIaaFasJFLHv7jQr4UqzacL%2FSLx2Fy3TcoS8Nh%2B470zyhgfZrfpff%2FRAD0vBHpDPuSoHFpZctDfjncBgm%2BPuuI21GItBP0bP8MMc4pOchbuYPoyXebEHHIXBMVA5RczE5pCTQoP6wsp%2BZro%3D%7Ctkp%3ABk9SR8S9uPefZQ'\n",
    "# product_name = 'Laptop Stand Alluminium'\n",
    "\n",
    "ebay_scrap(start_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
