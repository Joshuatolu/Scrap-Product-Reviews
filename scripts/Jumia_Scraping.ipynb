{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap Data for Mouse on Jumia\n",
    "\n",
    "#### To Do\n",
    "- Search for laptop mouse on Jumia and manually check for results that have good amount of reviews.\n",
    "    - for this test, I will search for just 1 result with a good number of reviews\n",
    "- get the url - [mouse link](https://www.jumia.com.ng/catalog/productratingsreviews/sku/GE779EA0A9NPFNAFAMZ/?page=1)\n",
    "- use the url to scrap all the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary Libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get the reviews on each page\n",
    "def get_page_review(driver):\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    reviews = soup.find_all('article', class_='-pvs -hr _bet')\n",
    "\n",
    "    # Extract review data\n",
    "    review_data = []\n",
    "    for review in reviews:\n",
    "        \n",
    "        # Reviewer Header Comment\n",
    "        try:\n",
    "            reviewer_header_comment = review.find('h3', class_ = '-m -fs16 -pvs').text\n",
    "        except AttributeError:\n",
    "            reviewer_header_comment = ''\n",
    "        \n",
    "        # Reviewer Detail Comment\n",
    "        try:\n",
    "            reviewer_detail_comment = review.find('p', class_ = '-pvs').text\n",
    "        except AttributeError:\n",
    "            reviewer_detail_comment = ''\n",
    "        \n",
    "        # Review Dates\n",
    "        try:\n",
    "            review_date = review.find('span', class_ = '-prs').text\n",
    "        except AttributeError:\n",
    "            review_date = ''\n",
    "        \n",
    "        # Reviewer Name\n",
    "        try:\n",
    "            div = review.find(\"div\", class_=\"-df -j-bet -i-ctr -gy5\")\n",
    "            reviewer_name = div.find_all('span')[1].text\n",
    "        except AttributeError:\n",
    "            reviewer_name = ''\n",
    "                \n",
    "        # product star\n",
    "        try:\n",
    "            product_star = review.find('div', class_ = 'stars _m _al -mvs').text\n",
    "        except AttributeError:\n",
    "            product_star = ''\n",
    "        \n",
    "        review_data.append({\n",
    "            'reviewer_name': reviewer_name,\n",
    "            'reviewer_header_comment': reviewer_header_comment,\n",
    "            'reviewer_detail_comment': reviewer_detail_comment,\n",
    "            'review_date': review_date,\n",
    "            'product_star': product_star\n",
    "        })\n",
    "    \n",
    "    return review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the scrap function\n",
    "def jumia_scrap(product_url, product_name):\n",
    "    # Clean product name incase it contains spaces\n",
    "    product_name = product_name.replace(' ', '_')\n",
    "    \n",
    "    # Configure Selenium EdgeDriver options\n",
    "    options = Options()\n",
    "    options.use_chromium = True\n",
    "    service = Service(executable_path=r'Driver\\msedgedriver.exe') # Always check to confirm that the version of edge driver matches the version or MS Edge browser\n",
    "    driver = webdriver.Edge(service=service, options=options) # Initialize the webdriver\n",
    "\n",
    "    driver.get(product_url)\n",
    "    time.sleep(10) # To load the product page\n",
    "\n",
    "    # Scrape all reviews - using a while loop\n",
    "    all_reviews = []\n",
    "\n",
    "    while True:\n",
    "        d_reviews = get_page_review(driver)\n",
    "        all_reviews.extend(d_reviews)\n",
    "\n",
    "        # Clicking the 'Next Page' button to get to other pages\n",
    "        try:\n",
    "            next_page_button = driver.find_element(By.XPATH, '//a[@aria-label=\"Next Page\"]')\n",
    "\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_page_button) # Scroll the page to view the button for Next Page\n",
    "            time.sleep(2)  # Wait for the scroll\n",
    "\n",
    "            next_page_button.click() # Clicks the next page button\n",
    "            time.sleep(10)  # Wait for the next page to load\n",
    "        except Exception as e:\n",
    "            print(\"No more pages to load\")\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "    # Save to CSV\n",
    "    product_df = pd.DataFrame(all_reviews)\n",
    "\n",
    "    output_dir = r'Reviews\\Jumia'\n",
    "    file_name = f'{product_name}_reviews.csv'\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    product_df.to_csv(output_path, index=False)\n",
    "    print(f'{len(product_df)} {product_name} reviews successfully written to {output_path}! Nice work!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages to load\n",
      "11 Ace_Laptop reviews successfully written to Reviews\\Jumia\\Ace_Laptop_reviews.csv! Nice work!!!\n"
     ]
    }
   ],
   "source": [
    "# Update the start URL\n",
    "start_url = 'https://www.jumia.com.ng/catalog/productratingsreviews/sku/AC431CL57R8EKNAFAMZ/' # small review data for testing\n",
    "# 'https://www.jumia.com.ng/catalog/productratingsreviews/sku/GE779EA1BY9XTNAFAMZ/' - more data\n",
    "product_name = 'Ace Laptop'\n",
    "\n",
    "jumia_scrap(start_url, product_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
